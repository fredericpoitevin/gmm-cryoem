{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display images in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our tools and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipyvolume as ipv\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from molecular_handling import particle\n",
    "from molecular_handling import generate_dataset\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from forward_modeling import project_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure we have a local directory to write the data in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = pathlib.Path('..') / 'data'  # directory where the data is\n",
    "output_dir = data_directory / 'test'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single particle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a particle with 3 atoms of radii 1, 2 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crds = np.array([[0.,5.,5.],[5.,5.,5.],[5.,5.,0.]])\n",
    "particle_ = particle(n_atom=3, rads_atom=[2.,2.,2.], crds = crds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a dataset from that particle and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images were created\n",
      "2000 images were created\n",
      "3000 images were created\n",
      "4000 images were created\n",
      "5000 images were created\n",
      "6000 images were created\n",
      "7000 images were created\n",
      "8000 images were created\n",
      "9000 images were created\n",
      "10000 images were created\n"
     ]
    }
   ],
   "source": [
    "data, metadata = generate_dataset(particle_, n_projections=10000, reldir=output_dir, print_frequency=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images were created\n",
      "2000 images were created\n",
      "3000 images were created\n",
      "4000 images were created\n",
      "5000 images were created\n",
      "6000 images were created\n",
      "7000 images were created\n",
      "8000 images were created\n",
      "9000 images were created\n",
      "10000 images were created\n"
     ]
    }
   ],
   "source": [
    "crds = np.array([[0.,5.,5.],[5.,5.,5.],[5.,5.,0.]])\n",
    "particle_ = particle(n_atom=3, rads_atom=[2.,2.,2.], crds = crds, size_grid=33)\n",
    "data, metadata = generate_dataset(particle_, n_projections=10000,keyword='particle_oddres', reldir=output_dir, print_frequency=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher \"resolution\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images were created\n"
     ]
    }
   ],
   "source": [
    "crds = np.array([[4.,7.,7.],[5.,3.,6.],[6.,6.,6.]])\n",
    "particle_ = particle(n_atom=3, rads_atom=[2.,2.,2.], crds = crds,size_grid=128)\n",
    "data, metadata = generate_dataset(particle_, n_projections=100, keyword='particle_hires', reldir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we have just written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/test/particle_hires_xyz.npy',\n",
       " '../data/test/particle_oddres_meta.npy',\n",
       " '../data/test/particle_hires_map.npy',\n",
       " '../data/test/particle_meta.npy',\n",
       " '../data/test/het_particle_meta.npy',\n",
       " '../data/test/particle_hires_data.npy',\n",
       " '../data/test/particle_hires_meta.npy',\n",
       " '../data/test/particle_map.npy',\n",
       " '../data/test/particle_oddres_data.npy',\n",
       " '../data/test/particle_xyz.npy',\n",
       " '../data/test/particle_oddres_map.npy',\n",
       " '../data/test/het_particle_data.npy',\n",
       " '../data/test/particle_oddres_xyz.npy',\n",
       " '../data/test/het_particle_map.npy',\n",
       " '../data/test/particle_data.npy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(f'{output_dir}/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogeneous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the conformations\n",
    "crds1 = np.array([[1.,7.,9.],[7.,7.,7.],[9.,7.,1.]])\n",
    "particle1 = particle(n_atom=3, rads_atom=[2.,3.,2.], crds = crds1, size_grid=33)\n",
    "particle1.create_map()\n",
    "crds2 = np.array([[1.,7.,7.],[7.,7.,7.],[7.,7.,1.]])\n",
    "particle2 = particle(n_atom=3, rads_atom=[2.,3., 2.], crds = crds2, size_grid=33)\n",
    "particle2.create_map()\n",
    "crds3 = np.array([[1.,7.,5.],[7.,7.,7.],[5.,7.,1.]])\n",
    "particle3 = particle(n_atom=3, rads_atom=[2.,3., 2.], crds = crds3, size_grid=33)\n",
    "particle3.create_map()\n",
    "import ipyvolume as ipv\n",
    "vols = np.array([particle1.volume, particle2.volume, particle3.volume])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelresplandy/miniconda3/envs/gmm-cryoem/lib/python3.6/site-packages/ipyvolume/serialize.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "  gradient = gradient / np.sqrt(gradient[0] ** 2 + gradient[1] ** 2 + gradient[2] ** 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a002e911cb2442d87d0cd350ff52fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(vols[0], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a07c742a6d49a48de819752a55c89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(vols[1], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9909924ae624ecab8796679ea53d619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(vols[2], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the covariance of each volume\n",
    "covs = np.array([np.identity(np.power(particle1.size_grid, 3))/50 for i in range(len(vols))])\n",
    "#cholesky decomposition for sample generation\n",
    "chol_covs = [np.linalg.cholesky(cov) for cov in covs]\n",
    "#mixture parameter\n",
    "pis = [0.2, 0.3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(mean, chol_cov):\n",
    "    return mean + chol_cov @ np.random.standard_normal(mean.size)\n",
    "\n",
    "def generate_dataset(vols, chol_covs, pis, size_dataset = 100, output_maps = True, reldir='.', keyword='het_particle', heterogeneity = True, print_frequency = 50):\n",
    "    N = vols.shape[-1]\n",
    "    pis = np.cumsum(pis)\n",
    "    dataset = np.zeros((size_dataset, N, N))\n",
    "    metadataset = np.zeros((size_dataset, 6))\n",
    "    \n",
    "    if output_maps: #needs to be called before rotating the particle\n",
    "        np.save(f'{reldir}/{keyword}_map', vols)\n",
    "    \n",
    "    if heterogeneity:\n",
    "        vols = vols.reshape(vols.shape[0], np.power(N, 3)\n",
    "                    )\n",
    "        \n",
    "    for i in range(len(dataset)):\n",
    "        p = np.random.random()\n",
    "        index = len(pis) - pis[pis-p>0].shape[0]\n",
    "        mean = vols[index]\n",
    "        chol_cov = chol_covs[index]\n",
    "        vol_sample = sample(mean, chol_cov).reshape((N,N,N))\n",
    "        \n",
    "        rotation =  R.random()\n",
    "        image = project_volume(vol_sample, rotation)\n",
    "        \n",
    "        dataset[i,...] = image\n",
    "        metadataset[i,0:3] = -np.array(rotation.as_rotvec())\n",
    "        metadataset[i,3] = N\n",
    "        metadataset[i,4] = len(vols)\n",
    "        metadataset[i,5] = index\n",
    "        \n",
    "        \n",
    "        if (i+1)%print_frequency == 0:\n",
    "            print(f'{str(i+1)} images were created')\n",
    "    \n",
    "    np.save(f'{reldir}/{keyword}_data', dataset) \n",
    "    np.save(f'{reldir}/{keyword}_meta', metadataset) \n",
    "    \n",
    "    return dataset, metadataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 images were created\n",
      "100 images were created\n",
      "150 images were created\n",
      "200 images were created\n",
      "250 images were created\n",
      "300 images were created\n"
     ]
    }
   ],
   "source": [
    "data, metadata = generate_dataset(vols, covs, pis, size_dataset = 300, reldir = output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
