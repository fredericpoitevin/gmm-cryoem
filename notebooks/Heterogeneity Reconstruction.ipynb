{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import ipyvolume as ipv\n",
    "import pathlib, glob\n",
    "from scipy.stats import norm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from molecular_handling import particle\n",
    "from forward_modeling import project_volume, slice_volume, rotate_volume, take_slice, project_volume_bis, backprojection, add_slice\n",
    "from scipy.interpolate import RegularGridInterpolator, griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory ../data/test exists: \n",
      ">>> ../data/test/particle_hires_xyz.npy\n",
      ">>> ../data/test/particle_oddres_meta.npy\n",
      ">>> ../data/test/particle_hires_map.npy\n",
      ">>> ../data/test/.DS_Store\n",
      ">>> ../data/test/particle_meta.npy\n",
      ">>> ../data/test/het_particle_meta.npy\n",
      ">>> ../data/test/particle_hires_data.npy\n",
      ">>> ../data/test/particle_hires_meta.npy\n",
      ">>> ../data/test/particle_map.npy\n",
      ">>> ../data/test/particle_oddres_data.npy\n",
      ">>> ../data/test/particle_xyz.npy\n",
      ">>> ../data/test/particle_oddres_map.npy\n",
      ">>> ../data/test/het_particle_data.npy\n",
      ">>> ../data/test/particle_oddres_xyz.npy\n",
      ">>> ../data/test/het_particle_map.npy\n",
      ">>> ../data/test/particle_data.npy\n"
     ]
    }
   ],
   "source": [
    "data_directory = pathlib.Path('..') / 'data'  # directory where the data is\n",
    "output_dir = data_directory / 'test'\n",
    "if output_dir.exists():\n",
    "    print(f'Data directory {output_dir} exists: ')\n",
    "    for x in list(output_dir.glob('*')):\n",
    "        print(f'>>> {str(x)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='het_particle'\n",
    "dataset     = np.load(f'{output_dir}/{keyword}_data.npy')\n",
    "metadataset = np.load(f'{output_dir}/{keyword}_meta.npy')\n",
    "volumes      = np.load(f'{output_dir}/{keyword}_map.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelresplandy/miniconda3/envs/gmm-cryoem/lib/python3.6/site-packages/ipyvolume/serialize.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "  gradient = gradient / np.sqrt(gradient[0] ** 2 + gradient[1] ** 2 + gradient[2] ** 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92348a8cf8da4d38b159fd7d2da47de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(volumes[0], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6f398a8bcb4b24835e1062e3276909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(volumes[1], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b931de0e88d4d70abfc1609fa429c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(volumes[2], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstructing volumes with variable $z_i$  and orientations known "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.9624619483947754, sum of voxels: 4230.554475289484\n",
      "sum of pixels for real volume: 4230.958957810194\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "vols_reconstructed = np.zeros(volumes.shape)\n",
    "for i in range(volumes.shape[0]):\n",
    "    index_i = (metadataset[:,5] == i)\n",
    "    vols_reconstructed[i] = backprojection(dataset[index_i], metadataset[index_i][:,0:3])\n",
    "end = time.time()\n",
    "print(f\"time: {end-start}, sum of voxels: {np.sum(vols_reconstructed)}\")\n",
    "print(f\"sum of pixels for real volume: {np.sum(volumes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e6784cbb044c6eaa6db1c20c90db95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(vols_reconstructed[0], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2237bfaddc1a40878906679a1be043bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(vols_reconstructed[1], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77d4b67a2894db3854fcd9b97276641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(vols_reconstructed[2], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstructing volumes with hidden variable $z_i$ unknown but orientations known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba(projected_vol, image, scale=10):\n",
    "    \"\"\"\n",
    "    This function calculates a probability score to tell how close two images are.\n",
    "    \"\"\"\n",
    "    return np.prod((1-norm.cdf(np.abs(projected_vol-image), loc=0, scale=scale))*2)\n",
    "\n",
    "def het_reconstruct(dataset, metadataset, vols, heterogeneity = False):\n",
    "    \"\"\"\n",
    "    This function reconstructs the models at step t+1 given the models at step t\n",
    "    To long, mainly because of the projection operator\n",
    "    \"\"\"    \n",
    "    \n",
    "    counts = np.zeros(vols.shape, dtype=complex)\n",
    "    next_models = np.zeros(vols.shape, dtype=complex)\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        images_i = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(dataset[i])))\n",
    "        rot = R.from_rotvec(-metadataset[i,0:3])                            \n",
    "        #Adding the i-th slice in the \"rot\"-rotated plane weighed by the similarity score \n",
    "        if heterogeneity:\n",
    "            prob = np.zeros(vols.shape[0])\n",
    "            for k in range(vols.shape[0]):\n",
    "                projected_vol = project_volume(vols[k], rot)\n",
    "                prob[k] = proba(projected_vol, dataset[i])\n",
    "                next_models[k], counts[k] = add_slice(next_models[k], counts[k], images_i, rot, prob = prob[k]) \n",
    "                #we add the image, weighed by the probabity\n",
    "                #to construct the models at the next iteration\n",
    "            #k_ = np.argmax(prob)\n",
    "            #next_models[k_], counts[k_] = add_slice(next_models[k_], counts[k_], images_i, rot) \n",
    "        else:\n",
    "            projected_vol = project_volume(vols, rot)\n",
    "            prob = proba(projected_vol, dataset[i])                                      \n",
    "            #probs+= prob\n",
    "            next_models, counts = add_slice(next_models, counts, images_i, rot, prob = prob)\n",
    "\n",
    "    \n",
    "    #Dividing by count to scale the solution/ taking the inverse fourier transform\n",
    "    if (heterogeneity):\n",
    "        for k in range(next_models.shape[0]):\n",
    "            counts[k][counts[k] == 0] = 1\n",
    "            next_models[k] = next_models[k]/counts[k]\n",
    "            next_models[k] = np.real(np.fft.fftshift(np.fft.ifftn(np.fft.fftshift(next_models[k]))))\n",
    "                                                        \n",
    "    else:\n",
    "        counts[counts == 0] = 1\n",
    "        next_models = next_models/counts\n",
    "        next_models = np.real(np.fft.fftshift(np.fft.ifftn(np.fft.fftshift(next_models))))\n",
    "        \n",
    "    return next_models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_vols_reconstructed = het_reconstruct(dataset, metadataset, volumes, heterogeneity = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelresplandy/miniconda3/envs/gmm-cryoem/lib/python3.6/site-packages/traitlets/traitlets.py:1985: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  value = float(value)\n",
      "/Users/michaelresplandy/miniconda3/envs/gmm-cryoem/lib/python3.6/site-packages/ipyvolume/serialize.py:100: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  subdata[..., 3] = (Im * 255).astype(np.uint8)\n",
      "/Users/michaelresplandy/miniconda3/envs/gmm-cryoem/lib/python3.6/site-packages/ipyvolume/serialize.py:102: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  subdata[..., i] = ((gradient[i][zindex] / 2.0 + 0.5) * 255).astype(np.uint8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c84d515e5d34309b684450b3aba286b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(het_vols_reconstructed[0], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404db2a573dd4c3bbb364314f705206c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(het_vols_reconstructed[1], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21456ca9fd17452990aa090fe9f3854e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.quickvolshow(het_vols_reconstructed[2], level=[0.25, 0.75], opacity=[0.03, 0.2], level_width=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
